{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a4c3a8",
   "metadata": {},
   "source": [
    "# Atividade: Treinamento de Redes Neurais com Keras (Dados Tabulares)\n",
    "\n",
    "Este notebook contém os dois exercícios solicitados:\n",
    "\n",
    "- Exercício 1 — Classificação Multiclasse (Wine dataset)\n",
    "- Exercício 2 — Regressão (California Housing dataset)\n",
    "\n",
    "Este material foi adaptado e organizado com base no notebook `FINAL_Exemplo_Redes_Neurais_Com_Keras.ipynb` (exemplo de introdução ao treinamento de redes neurais).\n",
    "\n",
    "Referências úteis (do material base):\n",
    "\n",
    "- https://www.deeplearningbook.com.br/algoritmo-backpropagation-parte-2-treinamento-de-redes-neurais/\n",
    "- https://keras.io/api/losses/\n",
    "- https://www.deeplearningbook.com.br/aprendizado-com-a-descida-do-gradiente/\n",
    "- https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21\n",
    "- https://www.deeplearningbook.com.br/funcao-de-ativacao/\n",
    "- https://keras.io/api/optimizers/\n",
    "\n",
    "Siga as células na ordem. Cada seção contém código executável e explicações. Recomenda-se usar um ambiente virtual com as dependências listadas em `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e357cd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Additional imports shown in the example notebook\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Section: Install (optional) and import libraries\n",
    "# Inspired by FINAL_Exemplo_Redes_Neurais_Com_Keras.ipynb\n",
    "\n",
    "# If you need to install packages from within the notebook, uncomment the pip lines below.\n",
    "# Note: in many setups it's better to install packages from the terminal.\n",
    "\n",
    "# !pip install -r atividade/requirements.txt\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "# Additional imports shown in the example notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "\n",
    "# Set plotting defaults\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Reproducibility seed\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232bf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package 'matplotlib' not found — installing...\n",
      "Package 'seaborn' not found — installing...\n",
      "Package 'seaborn' not found — installing...\n",
      "Installed/loaded: matplotlib 3.10.6 seaborn 0.13.2\n",
      "Installed/loaded: matplotlib 3.10.6 seaborn 0.13.2\n"
     ]
    }
   ],
   "source": [
    "# Ensure matplotlib and seaborn are installed and importable\n",
    "# This installs into the same Python interpreter used by the notebook kernel.\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def ensure_pkg(pkg_name):\n",
    "    try:\n",
    "        return importlib.import_module(pkg_name)\n",
    "    except Exception:\n",
    "        print(f\"Package '{pkg_name}' not found — installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg_name])\n",
    "        return importlib.import_module(pkg_name)\n",
    "\n",
    "matplotlib = ensure_pkg('matplotlib')\n",
    "seaborn = ensure_pkg('seaborn')\n",
    "print('Installed/loaded:', 'matplotlib', matplotlib.__version__, 'seaborn', seaborn.__version__)\n",
    "\n",
    "# After running this cell, if imports still fail, restart the kernel and re-run the notebook cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Utility functions and constants\n",
    "import time\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "\n",
    "def plot_history(history, title: str = 'Training history'):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # loss\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title(title + ' - loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # metric (accuracy or mae) - try common keys\n",
    "    plt.subplot(1,2,2)\n",
    "    if 'accuracy' in history.history:\n",
    "        plt.plot(history.history['accuracy'], label='train_acc')\n",
    "        if 'val_accuracy' in history.history:\n",
    "            plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "        plt.title(title + ' - accuracy')\n",
    "        plt.legend()\n",
    "    elif 'mae' in history.history:\n",
    "        plt.plot(history.history['mae'], label='train_mae')\n",
    "        if 'val_mae' in history.history:\n",
    "            plt.plot(history.history['val_mae'], label='val_mae')\n",
    "        plt.title(title + ' - MAE')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Constants\n",
    "CLASSIFICATION_INPUTS = None\n",
    "REGRESSION_INPUTS = None\n",
    "\n",
    "print('Utility functions defined.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7659b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Section: Load and inspect data (Wine dataset for classification)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_wine\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Section: Load and inspect data (Wine dataset for classification)\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "print('Wine dataset loaded:')\n",
    "print('  Shape:', X.shape)\n",
    "print('  Classes:', np.unique(y))\n",
    "print('  Feature names:', wine.feature_names)\n",
    "\n",
    "# quick head using pandas DataFrame\n",
    "df_wine = pd.DataFrame(X, columns=wine.feature_names)\n",
    "df_wine['target'] = y\n",
    "\n",
    "display(df_wine.head())\n",
    "\n",
    "a = df_wine.describe().T\n",
    "print('\\nFeature summary (first rows):')\n",
    "print(a.head())\n",
    "\n",
    "# Train/test split and scaling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "print('\\nTrain/test sizes:', X_train_s.shape, X_test_s.shape)\n",
    "CLASSIFICATION_INPUTS = X_train_s.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf63b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Build, train and evaluate Keras model (Classification)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Build model\n",
    "model_clf = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(CLASSIFICATION_INPUTS,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "model_clf.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_clf.summary()\n",
    "\n",
    "# Prepare labels\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=3)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history_clf = model_clf.fit(X_train_s, y_train_cat, validation_split=0.1, epochs=200, batch_size=16, callbacks=[es], verbose=2)\n",
    "\n",
    "plot_history(history_clf, title='Keras Classification')\n",
    "\n",
    "# Evaluate\n",
    "keras_preds = np.argmax(model_clf.predict(X_test_s), axis=1)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print('Keras accuracy:', accuracy_score(y_test, keras_preds))\n",
    "print('\\nClassification report (Keras):')\n",
    "print(classification_report(y_test, keras_preds, target_names=wine.target_names))\n",
    "\n",
    "# scikit-learn baseline: RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    "rf.fit(X_train_s, y_train)\n",
    "rf_preds = rf.predict(X_test_s)\n",
    "print('\\nRandomForest accuracy:', accuracy_score(y_test, rf_preds))\n",
    "print('\\nClassification report (RandomForest):')\n",
    "print(classification_report(y_test, rf_preds, target_names=wine.target_names))\n",
    "\n",
    "print('\\nSummary:')\n",
    "print('  Keras accuracy:', accuracy_score(y_test, keras_preds))\n",
    "print('  RandomForest accuracy:', accuracy_score(y_test, rf_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Load and inspect data (California Housing for regression)\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "cal = fetch_california_housing()\n",
    "Xr = cal.data\n",
    "yr = cal.target\n",
    "\n",
    "print('California Housing dataset loaded:')\n",
    "print('  Shape:', Xr.shape)\n",
    "print('  Feature names:', cal.feature_names)\n",
    "\n",
    "df_cal = pd.DataFrame(Xr, columns=cal.feature_names)\n",
    "df_cal['target'] = yr\n",
    "\n",
    "display(df_cal.head())\n",
    "print(df_cal.describe().T.head())\n",
    "\n",
    "# Split and scale\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.2, random_state=RANDOM_STATE)\n",
    "scaler_r = StandardScaler()\n",
    "Xr_train_s = scaler_r.fit_transform(Xr_train)\n",
    "Xr_test_s = scaler_r.transform(Xr_test)\n",
    "\n",
    "REGRESSION_INPUTS = Xr_train_s.shape[1]\n",
    "print('Train/test sizes:', Xr_train_s.shape, Xr_test_s.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Build, train and evaluate Keras model (Regression)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_reg = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(REGRESSION_INPUTS,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model_reg.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model_reg.summary()\n",
    "\n",
    "es_r = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history_reg = model_reg.fit(Xr_train_s, yr_train, validation_split=0.1, epochs=200, batch_size=32, callbacks=[es_r], verbose=2)\n",
    "\n",
    "plot_history(history_reg, title='Keras Regression')\n",
    "\n",
    "# Evaluate Keras\n",
    "keras_r_preds = model_reg.predict(Xr_test_s).ravel()\n",
    "keras_r_rmse = rmse(yr_test, keras_r_preds)\n",
    "keras_r_mae = mean_absolute_error(yr_test, keras_r_preds)\n",
    "print('Keras Regression RMSE:', keras_r_rmse)\n",
    "print('Keras Regression MAE:', keras_r_mae)\n",
    "\n",
    "# scikit-learn baselines\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(Xr_train_s, yr_train)\n",
    "lr_preds = lr.predict(Xr_test_s)\n",
    "lr_rmse = rmse(yr_test, lr_preds)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rf.fit(Xr_train_s, yr_train)\n",
    "rf_preds = rf.predict(Xr_test_s)\n",
    "rf_rmse = rmse(yr_test, rf_preds)\n",
    "\n",
    "print('\\nLinearRegression RMSE:', lr_rmse)\n",
    "print('RandomForestRegressor RMSE:', rf_rmse)\n",
    "\n",
    "print('\\nSummary RMSEs:')\n",
    "print('  Keras:', keras_r_rmse)\n",
    "print('  LinearRegression:', lr_rmse)\n",
    "print('  RandomForest:', rf_rmse)\n",
    "\n",
    "# Plot predicted vs actual for best model (by RMSE)\n",
    "best_name, best_rmse = min((('Keras', keras_r_rmse), ('LinearRegression', lr_rmse), ('RandomForest', rf_rmse)), key=lambda x: x[1])\n",
    "print('\\nBest model by RMSE:', best_name)\n",
    "\n",
    "if best_name == 'Keras':\n",
    "    y_pred_best = keras_r_preds\n",
    "elif best_name == 'LinearRegression':\n",
    "    y_pred_best = lr_preds\n",
    "else:\n",
    "    y_pred_best = rf_preds\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(yr_test, y_pred_best, alpha=0.4)\n",
    "plt.plot([yr_test.min(), yr_test.max()], [yr_test.min(), yr_test.max()], 'r--')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title(f'Predicted vs Actual ({best_name})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d172a84",
   "metadata": {},
   "source": [
    "## Discussão e próximos passos\n",
    "\n",
    "- Os resultados apresentados acima comparam redes neurais em Keras com modelos clássicos do scikit-learn.\n",
    "- Para comparações mais robustas, execute múltiplas sementes, ou use cross-validation.\n",
    "- Salve modelos e pipelines usando `joblib` (scikit-learn) e `model.save()` (Keras) antes de entregar.\n",
    "\n",
    "Exemplo rápido para salvar modelos:\n",
    "\n",
    "```python\n",
    "# scikit-learn\n",
    "# joblib.dump(rf, 'rf_model.joblib')\n",
    "\n",
    "# Keras\n",
    "# model_reg.save('keras_reg_model.h5')\n",
    "```\n",
    "\n",
    "Boa prática: documente as versões dos pacotes e capture o ambiente (`pip freeze > requirements.txt`) para reprodutibilidade."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
